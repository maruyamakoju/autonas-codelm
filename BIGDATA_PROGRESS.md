# BigData Training Progress

**Date**: 2025-12-08
**Goal**: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚ºæ‹¡å¤§ã«ã‚ˆã‚‹ãƒ¢ãƒ¼ãƒ‰å´©å£Šã®è§£æ±º
**Status**: Phase 1 (å°è¦æ¨¡ãƒ†ã‚¹ãƒˆ) å®Ÿè¡Œä¸­

---

## ğŸ“Š Current Status

### Phase 1: Small-scale Test (7.92MB corpus)

**ãƒ‡ãƒ¼ã‚¿åé›†** âœ… COMPLETED
- ãƒªãƒã‚¸ãƒˆãƒª: requests, flask, pytest, boto3, fastapi
- ãƒ•ã‚¡ã‚¤ãƒ«æ•°: 1,535 Python files
- ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: **7.92 MB** (å…ƒã®1.3MBã‹ã‚‰ **6å€å¢—**)
  - Train: 7.79 MB (1,520 files, 246,144 lines)
  - Val: 0.13 MB (15 files, 3,630 lines)

**ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°** ğŸ”„ RUNNING
```bash
Experiment: v1_bigdata_test
Steps: 5,000 (å…ƒã®10K stepã®åŠåˆ†ã€æ§˜å­è¦‹)
Dataset: code_char_big (7.92 MB)
Device: cuda:0
Log: logs/train_v1_bigdata_test/
```

**æœŸå¾…ã•ã‚Œã‚‹çµæœ**:
- å…ƒãƒ‡ãƒ¼ã‚¿(1.3MB): Mode collapse 85.2%, Keywords 0%
- 6å€ãƒ‡ãƒ¼ã‚¿(7.92MB): Mode collapse <70%?, Keywords >5%?
- ãƒ‡ãƒ¼ã‚¿ãŒå°ã•ã™ãã‚‹ã®ã§åŠ‡çš„æ”¹å–„ã¯æœŸå¾…ã—ãªã„ãŒã€**å‚¾å‘**ã‚’è¦‹ã‚‹

---

## ğŸ› ï¸ Infrastructure Ready

### ãƒ„ãƒ¼ãƒ«å®Œæˆ âœ…

| Tool | Status | Purpose |
|------|--------|---------|
| `scripts/prepare_python_corpus.py` | âœ… | å¤§è¦æ¨¡ã‚³ãƒ¼ãƒ‘ã‚¹ç”Ÿæˆ |
| `data/DATA_COLLECTION_GUIDE.md` | âœ… | ãƒ‡ãƒ¼ã‚¿åé›†ã‚¬ã‚¤ãƒ‰ |
| `nas/EXPERIMENTS.md` Section 12 | âœ… | BigDataå®Ÿé¨“æ‰‹é †æ›¸ |
| `eval/` pipeline | âœ… | ãƒãƒƒãƒè©•ä¾¡ãƒ»è§£æ |

### ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç¢ºç«‹ âœ…

```bash
# 1. ãƒ‡ãƒ¼ã‚¿åé›†
cd data/raw_python
git clone <repos>

# 2. ã‚³ãƒ¼ãƒ‘ã‚¹ç”Ÿæˆ
cd ../../nas
python scripts/prepare_python_corpus.py \
  --src_dir ../data/raw_python \
  --train_out ../data/code_char_big/train.txt \
  --val_out ../data/code_char_big/val.txt

# 3. ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
python train_best.py \
  --arch_json models/codenas_best_current.json \
  --experiment_name v1_bigdata_char \
  --train_path ../data/code_char_big/train.txt \
  --max_steps 100000

# 4. è©•ä¾¡
python eval_playground.py \
  --checkpoint logs/train_v1_bigdata_char/*.pt \
  --eval_file eval/prompts/simple_python.txt \
  --output eval/results_bigdata.jsonl

python eval/inspect_results.py eval/results_bigdata.jsonl
```

---

## ğŸ“ˆ Next Steps

### Immediate (Phase 1 å®Œäº†å¾Œ)

1. **Phase 1 çµæœã‚’ç¢ºèª** (~5-10åˆ†å¾Œ)
   ```bash
   cd nas
   python eval_playground.py \
     --checkpoint logs/train_v1_bigdata_test/v1_bigdata_test_best.pt \
     --eval_file eval/prompts/simple_python.txt \
     --output eval/results_bigdata_test.jsonl

   python eval/inspect_results.py eval/results_bigdata_test.jsonl --show_quality_examples
   ```

2. **çµæœã‚’åˆ†æ**
   - Mode collapseç‡ã®å¤‰åŒ–
   - Python keywordså‡ºç¾ç‡
   - ç”Ÿæˆå“è³ªã®ä¸»è¦³è©•ä¾¡

3. **Phase 2 ã‚’æ±ºå®š**:
   - âœ… **æ”¹å–„ã‚ã‚Š** â†’ ã•ã‚‰ã«ãƒ‡ãƒ¼ã‚¿ã‚’é›†ã‚ã¦50-100MBã¸
   - âš ï¸ **æ”¹å–„ä¸ååˆ†** â†’ Token-level modeling ã¸åˆ‡ã‚Šæ›¿ãˆæ¤œè¨

### Phase 2: Large-scale Training (50-100MB)

**ãƒ‡ãƒ¼ã‚¿åé›†ã‚ªãƒ—ã‚·ãƒ§ãƒ³**:

| Option | Size | Effort | Time |
|--------|------|--------|------|
| **A: GitHub repos (15-20å€‹)** | 50-100MB | Low | 10-30åˆ† |
| **B: The Stack dataset** | 100MB-1GB | Medium | 1-2æ™‚é–“ |
| **C: CodeSearchNet** | 500MB | High | 2-3æ™‚é–“ |

**æ¨å¥¨**: ã¾ãšOption Aï¼ˆGitHub reposè¿½åŠ ï¼‰ã§50-100MBã‚’ç›®æŒ‡ã™

**è¿½åŠ å€™è£œãƒªãƒã‚¸ãƒˆãƒª**:
```bash
cd data/raw_python

# ML/Data Scienceç³» (å¤§ãã‚)
git clone --depth 1 https://github.com/scikit-learn/scikit-learn.git  # ~30MB
git clone --depth 1 https://github.com/pandas-dev/pandas.git           # ~40MB
git clone --depth 1 https://github.com/numpy/numpy.git                 # ~30MB

# Web frameworks
git clone --depth 1 https://github.com/django/django.git               # ~15MB
git clone --depth 1 https://github.com/tornadoweb/tornado.git          # ~2MB
git clone --depth 1 https://github.com/aio-libs/aiohttp.git            # ~5MB

# Tools
git clone --depth 1 https://github.com/pypa/pip.git                    # ~5MB
git clone --depth 1 https://github.com/python-poetry/poetry.git        # ~3MB
git clone --depth 1 https://github.com/celery/celery.git               # ~5MB

# Testing
git clone --depth 1 https://github.com/robotframework/robotframework.git
git clone --depth 1 https://github.com/tox-dev/tox.git

# åˆè¨ˆ: 50-100MBé”æˆå¯èƒ½
```

### Phase 3: Full-scale (100K steps, 100MB+ data)

```bash
cd nas

python train_best.py \
  --arch_json models/codenas_best_current.json \
  --experiment_name v1_bigdata_production \
  --train_path ../data/code_char_big/train.txt \
  --val_path ../data/code_char_big/val.txt \
  --max_steps 100000 \
  --log_dir logs/train_v1_bigdata_production \
  --device cuda:0

# æœŸå¾…å­¦ç¿’æ™‚é–“: 1-2æ™‚é–“ (100MB data, 100K steps)
```

---

## ğŸ¯ Success Criteria

| Metric | Baseline (1.3MB) | Target (100MB+) | Phase 1 (7.92MB) |
|--------|------------------|-----------------|------------------|
| Mode collapseç‡ | 85.2% | <30% | TBD |
| Keywordså‡ºç¾ç‡ | 0% | >50% | TBD |
| Repetitionæ¯”ç‡ | 92.22% | <30% | TBD |
| Unique chars (avg) | 2.1 | >20 | TBD |

---

## ğŸ“ Lessons Learned

### Infrastructure Phase (å®Œäº†)

1. **ã‚³ãƒ¼ãƒ‘ã‚¹ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ** ãŒæ­£å¸¸å‹•ä½œ
   - 1,535 fileså‡¦ç† (æ•°ç§’)
   - ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚° âœ“
   - é™¤å¤–ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ âœ“

2. **æ—¢å­˜ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³** ãŒãã®ã¾ã¾ä½¿ãˆã‚‹
   - train_best.py ã¯æ–°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§è¿½åŠ å¤‰æ›´ä¸è¦
   - eval_playground.py ã‚‚ãã®ã¾ã¾å†åˆ©ç”¨å¯èƒ½
   - è©•ä¾¡ãƒ„ãƒ¼ãƒ« (inspect_results.py) ã‚‚æµç”¨

3. **Git cloneã‚¢ãƒ—ãƒ­ãƒ¼ãƒ** ãŒç°¡å˜ãƒ»é«˜å“è³ª
   - 5ãƒªãƒã‚¸ãƒˆãƒªã§ 7.92MBï¼ˆ10-15åˆ†ï¼‰
   - 15-20ãƒªãƒã‚¸ãƒˆãƒªã§ 50-100MBè¦‹è¾¼ã¿

### æ¬¡ã®ãƒ•ã‚§ãƒ¼ã‚ºã§æ¤œè¨¼ã™ã‚‹ã“ã¨

1. **ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º vs å“è³ªã®é–¢ä¿‚**
   - 7.92MB â†’ ã©ã®ç¨‹åº¦æ”¹å–„ã™ã‚‹ã‹ï¼Ÿ
   - 50MB â†’ åŠ‡çš„æ”¹å–„ã®é–¾å€¤ï¼Ÿ
   - 100MB â†’ ååˆ†ãªã®ã‹ã€ãã‚Œã¨ã‚‚1GBå¿…è¦ï¼Ÿ

2. **Char-level ã®é™ç•Œ**
   - 100MBã§ã‚‚ãƒ€ãƒ¡ãªã‚‰ â†’ Token-level ã¸
   - Token-level ãªã‚‰ 10-20MB ã§åŒç­‰å“è³ªã®å¯èƒ½æ€§

3. **Training steps ã®æœ€é©å€¤**
   - 10K steps (ç¾çŠ¶) â†’ ä¸è¶³ï¼Ÿ
   - 100K steps â†’ éå‰°ï¼Ÿ
   - Early stopping ãŒé©åˆ‡ã«æ©Ÿèƒ½ã™ã‚‹ã‹ï¼Ÿ

---

## ğŸ”— References

- [EXPERIMENTS.md Section 12](nas/EXPERIMENTS.md#12-bigdata-training-ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå®Ÿé¨“)
- [DATA_COLLECTION_GUIDE.md](data/DATA_COLLECTION_GUIDE.md)
- [EVALUATION_SUMMARY.md](nas/eval/EVALUATION_SUMMARY.md)

---

**Last Updated**: 2025-12-08
**Status**: Phase 1 training running, ~5min ETA
