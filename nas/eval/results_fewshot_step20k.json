{
  "checkpoint": "logs/train_v1_8k_strongreg/v1_8k_strongreg_best.pt",
  "step": 19500,
  "val_loss": 1.2617148704111119,
  "categories": {
    "function": [
      {
        "prompt": "def subtract(a, b):",
        "sample_idx": 0,
        "output": "\n    \"\"\"\n    self._a_a = (a_a_a_a, config, index)\n    # GH#57444457,4747674747,7444,47444,",
        "collapsed": false,
        "collapse_pattern": null
      },
      {
        "prompt": "def subtract(a, b):",
        "sample_idx": 1,
        "output": "\n    \"\"\"\n    # We is used to only f\"\n    return (a + 0\n    data_a = self.a.aa(a)\n    def test_a_a_a_a_a_a_a_a_a_a_",
        "collapsed": false,
        "collapse_pattern": null
      },
      {
        "prompt": "def divide(a, b):",
        "sample_idx": 0,
        "output": "\n    def __a__(self, config, config):\n        super().__init__()\n        self._prepare_config_and_and_and_and_and_and_and_and_and_and_and_and_and_and_",
        "collapsed": false,
        "collapse_pattern": null
      },
      {
        "prompt": "def divide(a, b):",
        "sample_idx": 1,
        "output": "\n    \"\"\"\n    b = be.e_bon(a, b)\n    b_1 = bon_a(a,b), b=a, b, b, b=a, b)\n    b = b.a_a(a,",
        "collapsed": false,
        "collapse_pattern": null
      },
      {
        "prompt": "def max_value(a, b):",
        "sample_idx": 0,
        "output": "\n    \"\"\"\n    return None\n    # We not use a ba of the model's ba-a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a",
        "collapsed": true,
        "collapse_pattern": "repeated '\"a\",'"
      },
      {
        "prompt": "def max_value(a, b):",
        "sample_idx": 1,
        "output": "\n    \"\"\"\n    return bis_value_value_value and bch_value_value\n\n    def test_value_value_value_value_value_value_value_value_value_value_value_value_va",
        "collapsed": false,
        "collapse_pattern": null
      },
      {
        "prompt": "def factorial(n):",
        "sample_idx": 0,
        "output": "\n    \"\"\"\n    def __a_b_a_b = None\n    return (\n        {\n            \"a\": {\"a\": np.ndarray, \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"",
        "collapsed": true,
        "collapse_pattern": "repeated '\"a\",'"
      },
      {
        "prompt": "def factorial(n):",
        "sample_idx": 1,
        "output": "\n    \"\"\"\n    the b', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', '",
        "collapsed": true,
        "collapse_pattern": "repeated ''a','"
      },
      {
        "prompt": "def is_even(n):",
        "sample_idx": 0,
        "output": "\n    is_b = (a_b_b_b_b_b_b_b_b_b_b_b_b_b_bbbabbbbbbbbbbbbbbbbbbbbb",
        "collapsed": false,
        "collapse_pattern": null
      },
      {
        "prompt": "def is_even(n):",
        "sample_idx": 1,
        "output": "\n    # GH#5745\n    # GH#4585\n\n    # GH#6\n    # GH#575\n\n    # GH#45667#4146,\n    # GH#66\n    # GH",
        "collapsed": false,
        "collapse_pattern": null
      }
    ],
    "class": [
      {
        "prompt": "class Timer:",
        "sample_idx": 0,
        "output": "\n    def _get_count_count_count_count(self, dtype):\n        \"\"\"\n        # TODO\n        self = self.get_count_count(self._no_count)\n        self.no_cou",
        "collapsed": false,
        "collapse_pattern": null
      },
      {
        "prompt": "class Timer:",
        "sample_idx": 1,
        "output": "\n    def __init__(self, config_and_count) -> None:\n        config, config:\n            config = config.and_and_and_and_and_and_and_and_and_and_and_and",
        "collapsed": false,
        "collapse_pattern": null
      },
      {
        "prompt": "class Stack:",
        "sample_idx": 0,
        "output": "\n    def __str__(self, config: int, config: int, config: int) -> torch: int: int: int, int: int: int) -> int: int: int: int: int = int\n        \"\"\" int",
        "collapsed": true,
        "collapse_pattern": "repeated 'int:'"
      },
      {
        "prompt": "class Stack:",
        "sample_idx": 1,
        "output": "\n    def __str__(self, config: torch) -> None:\n        \"\"\"\n        self.config = config.v2\n        self.num_labels = config.num_labels\n        self.nu",
        "collapsed": false,
        "collapse_pattern": null
      },
      {
        "prompt": "class Queue:",
        "sample_idx": 0,
        "output": "\n    def __init__(self, config: int):\n        super().__init__(self, config: int):\n            self.num_labels = config.num_labels\n        self.num_la",
        "collapsed": false,
        "collapse_pattern": null
      },
      {
        "prompt": "class Queue:",
        "sample_idx": 1,
        "output": "\n    def __init__(self, config: int):\n        super().__init__(config)\n        self.config = config\n        self.config = config\n        self.config =",
        "collapsed": false,
        "collapse_pattern": null
      }
    ],
    "algorithm": [
      {
        "prompt": "def linear_search(arr, target):",
        "sample_idx": 0,
        "output": "\n    if isinstance(arr, np.ndarray) and np.ndarray) and self.assert_index_len_columns_columns_columns_columns_columns\n    def test_columns_columns_col",
        "collapsed": false,
        "collapse_pattern": null
      },
      {
        "prompt": "def linear_search(arr, target):",
        "sample_idx": 1,
        "output": "\n    def test_frame_name_name_frame_name_name(self, size, dtype: bool) -> None:\n        # We is a copy of the number of the `\n            `name` is a ",
        "collapsed": false,
        "collapse_pattern": null
      },
      {
        "prompt": "def bubble_sort(arr):",
        "sample_idx": 0,
        "output": "\n    # GH#57\n    # GH#4865\n    #6414)\n    x = np.array([\n        np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray)\n\n   ",
        "collapsed": true,
        "collapse_pattern": "repeated 'np.ndarray,'"
      },
      {
        "prompt": "def bubble_sort(arr):",
        "sample_idx": 1,
        "output": "\n    def/test_test_test_test_test_test_test_test_test_test_test_test_test_test_test_test_test_test_test_test_test_test_test_test_test_test_test_test_",
        "collapsed": false,
        "collapse_pattern": null
      },
      {
        "prompt": "def reverse_list(arr):",
        "sample_idx": 0,
        "output": "\n    def test_columns_mask_kwargs_columns(self, config_columns, index: torch.Tensor):\n        # TODO: x for k, k, k in k-val:\n            # We in the ",
        "collapsed": false,
        "collapse_pattern": null
      },
      {
        "prompt": "def reverse_list(arr):",
        "sample_idx": 1,
        "output": "\n    def test_s_name_name_name_name(self, dtype: int) -> None:\n        \"\"\"\n        if not is_name:\n            self.get_name = None\n\n        # We are ",
        "collapsed": false,
        "collapse_pattern": null
      }
    ]
  },
  "summary": {
    "total_samples": 22,
    "collapsed_samples": 5,
    "collapse_rate": 0.22727272727272727
  }
}