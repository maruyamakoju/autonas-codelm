{
  "experiment_name": "v1_token_test",
  "final_metrics": {
    "val_loss": 0.03489381821543767,
    "val_ppl": 1.0355097506886926,
    "best_val_loss": 0.03489381821543767,
    "num_params": 28355328,
    "model_size_mb": 54.08349609375,
    "latency_ms": 7.30593204498291,
    "total_steps": 5000,
    "train_time_s": 589.3040471076965,
    "train_time_min": 9.82173411846161,
    "architecture": {
      "arch_type": "transformer",
      "num_layers": 4,
      "hidden_dim": 256,
      "num_heads": 8,
      "ffn_multiplier": 3.0,
      "normalization": "rmsnorm",
      "activation": "gelu",
      "position_encoding": "rope",
      "attention_dropout": 0.1,
      "residual_dropout": 0.1,
      "vocab_size": 50257,
      "max_seq_length": 256,
      "quantization": "fp16",
      "pruning_ratio": 0.0
    }
  },
  "total_steps": 60,
  "all_metrics": [
    {
      "step": 100,
      "timestamp": 1765241559.1794071,
      "train_loss": 8.098012828826905,
      "train_ppl": 3287.927903666386,
      "lr": 0.00015,
      "grad_norm": 7.499585151672363,
      "steps_per_sec": 11.984065719350266
    },
    {
      "step": 200,
      "timestamp": 1765241566.017343,
      "train_loss": 3.9131077885627747,
      "train_ppl": 50.05426858623324,
      "lr": 0.0003,
      "grad_norm": 2.1300570964813232,
      "steps_per_sec": 13.173283984943028
    },
    {
      "step": 300,
      "timestamp": 1765241572.5607116,
      "train_loss": 1.7842032676935196,
      "train_ppl": 5.954833648721187,
      "lr": 0.0002996895438695975,
      "grad_norm": 0.7656508684158325,
      "steps_per_sec": 13.808503696651071
    },
    {
      "step": 400,
      "timestamp": 1765241579.1133065,
      "train_loss": 0.8188191854953766,
      "train_ppl": 2.2678203806735997,
      "lr": 0.0002987595048992025,
      "grad_norm": 0.6680335998535156,
      "steps_per_sec": 14.145104800328275
    },
    {
      "step": 500,
      "timestamp": 1765241585.6607895,
      "train_loss": 0.4377218985557556,
      "train_ppl": 1.5491740199747346,
      "lr": 0.00029721386565846836,
      "grad_norm": 0.5049238801002502,
      "steps_per_sec": 14.35717642863251
    },
    {
      "step": 500,
      "timestamp": 1765241633.5581648,
      "val_loss": 0.28374108424263733,
      "val_ppl": 1.3280890230579052
    },
    {
      "step": 600,
      "timestamp": 1765241641.7094235,
      "train_loss": 0.265687835663557,
      "train_ppl": 1.3043278304974646,
      "lr": 0.00029505924481191485,
      "grad_norm": 0.34105241298675537,
      "steps_per_sec": 6.602516237427567
    },
    {
      "step": 700,
      "timestamp": 1765241648.3751159,
      "train_loss": 0.18062834285199642,
      "train_ppl": 1.197969862483253,
      "lr": 0.0002923048687767903,
      "grad_norm": 0.2122916430234909,
      "steps_per_sec": 7.176539731863939
    },
    {
      "step": 800,
      "timestamp": 1765241654.9386804,
      "train_loss": 0.13321427017450332,
      "train_ppl": 1.14249477466056,
      "lr": 0.00028896253221413656,
      "grad_norm": 0.22283431887626648,
      "steps_per_sec": 7.684650130289946
    },
    {
      "step": 900,
      "timestamp": 1765241661.482565,
      "train_loss": 0.10713784519582986,
      "train_ppl": 1.1130876776936636,
      "lr": 0.0002850465475222398,
      "grad_norm": 0.1516696810722351,
      "steps_per_sec": 8.133932039219983
    },
    {
      "step": 1000,
      "timestamp": 1765241668.0395987,
      "train_loss": 0.08573267936706543,
      "train_ppl": 1.0895150395231554,
      "lr": 0.0002805736835487436,
      "grad_norm": 0.10752375423908234,
      "steps_per_sec": 8.532086414869305
    },
    {
      "step": 1000,
      "timestamp": 1765241715.9095795,
      "val_loss": 0.08727161621997463,
      "val_ppl": 1.091193025195103
    },
    {
      "step": 1100,
      "timestamp": 1765241724.1497245,
      "train_loss": 0.07316711083054543,
      "train_ppl": 1.0759103181594485,
      "lr": 0.00027556309378386906,
      "grad_norm": 0.11771143972873688,
      "steps_per_sec": 6.346834415132419
    },
    {
      "step": 1200,
      "timestamp": 1765241731.2349515,
      "train_loss": 0.06332806352525949,
      "train_ppl": 1.0653762930090647,
      "lr": 0.0002700362343422291,
      "grad_norm": 0.09302910417318344,
      "steps_per_sec": 6.651887589455526
    },
    {
      "step": 1300,
      "timestamp": 1765241737.7805748,
      "train_loss": 0.05662122568115592,
      "train_ppl": 1.0582548946951063,
      "lr": 0.0002640167720844517,
      "grad_norm": 0.09573977440595627,
      "steps_per_sec": 6.953895467942769
    },
    {
      "step": 1400,
      "timestamp": 1765241744.3254936,
      "train_loss": 0.04956480572000146,
      "train_ppl": 1.0508136887459647,
      "lr": 0.0002575304832720494,
      "grad_norm": 0.06713751703500748,
      "steps_per_sec": 7.235496780401568
    },
    {
      "step": 1500,
      "timestamp": 1765241750.8765426,
      "train_loss": 0.04555311515927315,
      "train_ppl": 1.0466065938135478,
      "lr": 0.00025060514318951,
      "grad_norm": 0.06445036083459854,
      "steps_per_sec": 7.498441861987823
    },
    {
      "step": 1500,
      "timestamp": 1765241798.784393,
      "val_loss": 0.05424467486716135,
      "val_ppl": 1.0557428843061902
    },
    {
      "step": 1600,
      "timestamp": 1765241806.8619153,
      "train_loss": 0.04189469145610929,
      "train_ppl": 1.0427846588343637,
      "lr": 0.00024327040720626447,
      "grad_norm": 0.060586340725421906,
      "steps_per_sec": 6.249342619441894
    },
    {
      "step": 1700,
      "timestamp": 1765241814.05153,
      "train_loss": 0.042828691992908716,
      "train_ppl": 1.0437590752473709,
      "lr": 0.0002355576837878423,
      "grad_norm": 0.06942053139209747,
      "steps_per_sec": 6.458559781808131
    },
    {
      "step": 1800,
      "timestamp": 1765241821.927077,
      "train_loss": 0.03903502123430371,
      "train_ppl": 1.0398068983335276,
      "lr": 0.00022749999999999997,
      "grad_norm": 0.05832666903734207,
      "steps_per_sec": 6.639810574267001
    },
    {
      "step": 1900,
      "timestamp": 1765241829.760167,
      "train_loss": 0.038819512706249955,
      "train_ppl": 1.0395828352240304,
      "lr": 0.00021913186008175518,
      "grad_norm": 0.06745480746030807,
      "steps_per_sec": 6.811861773430664
    },
    {
      "step": 2000,
      "timestamp": 1765241837.568163,
      "train_loss": 0.037224895749241114,
      "train_ppl": 1.0379264198317977,
      "lr": 0.000210489097692938,
      "grad_norm": 0.06940412521362305,
      "steps_per_sec": 6.975125410741126
    },
    {
      "step": 2000,
      "timestamp": 1765241873.9668305,
      "val_loss": 0.04625658121590177,
      "val_ppl": 1.0473431050518949
    },
    {
      "step": 2100,
      "timestamp": 1765241877.6649203,
      "train_loss": 0.037465649843215945,
      "train_ppl": 1.0381763349494537,
      "lr": 0.0002016087224689584,
      "grad_norm": 0.06318922340869904,
      "steps_per_sec": 6.425359458467405
    },
    {
      "step": 2200,
      "timestamp": 1765241880.7663262,
      "train_loss": 0.03476043950766325,
      "train_ppl": 1.0353716449466452,
      "lr": 0.00019252876153986548,
      "grad_norm": 0.05531185120344162,
      "steps_per_sec": 6.6680532410272875
    },
    {
      "step": 2300,
      "timestamp": 1765241883.894715,
      "train_loss": 0.03259781379252672,
      "train_ppl": 1.0331349430488264,
      "lr": 0.0001832880966923386,
      "grad_norm": 0.06609208136796951,
      "steps_per_sec": 6.905667627472901
    },
    {
      "step": 2400,
      "timestamp": 1765241886.9758577,
      "train_loss": 0.03213934514671564,
      "train_ppl": 1.0326613916330796,
      "lr": 0.0001739262978719075,
      "grad_norm": 0.06246381253004074,
      "steps_per_sec": 7.13986302682996
    },
    {
      "step": 2500,
      "timestamp": 1765241890.0497637,
      "train_loss": 0.030838216887786984,
      "train_ppl": 1.0313186404497083,
      "lr": 0.00016448345373837076,
      "grad_norm": 0.06259817630052567,
      "steps_per_sec": 7.369961180199011
    },
    {
      "step": 2500,
      "timestamp": 1765241914.511193,
      "val_loss": 0.040078724050577746,
      "val_ppl": 1.0408927142577022
    },
    {
      "step": 2600,
      "timestamp": 1765241918.092469,
      "train_loss": 0.030299964528530836,
      "train_ppl": 1.0307636801260915,
      "lr": 0.000155,
      "grad_norm": 0.051390331238508224,
      "steps_per_sec": 7.079502089036626
    },
    {
      "step": 2700,
      "timestamp": 1765241921.4119327,
      "train_loss": 0.0298482905048877,
      "train_ppl": 1.0302982160741876,
      "lr": 0.00014551654626162924,
      "grad_norm": 0.06748601794242859,
      "steps_per_sec": 7.2859361349399885
    },
    {
      "step": 2800,
      "timestamp": 1765241924.7021475,
      "train_loss": 0.03024800442159176,
      "train_ppl": 1.0307101229264743,
      "lr": 0.00013607370212809255,
      "grad_norm": 0.06460567563772202,
      "steps_per_sec": 7.48929083748064
    },
    {
      "step": 2900,
      "timestamp": 1765241928.230553,
      "train_loss": 0.02833568354137242,
      "train_ppl": 1.0287409578747693,
      "lr": 0.0001267119033076614,
      "grad_norm": 0.05178588256239891,
      "steps_per_sec": 7.684245150184012
    },
    {
      "step": 3000,
      "timestamp": 1765241931.3461237,
      "train_loss": 0.027306088972836734,
      "train_ppl": 1.0276823168511542,
      "lr": 0.00011747123846013447,
      "grad_norm": 0.05170762166380882,
      "steps_per_sec": 7.884131442592232
    },
    {
      "step": 3000,
      "timestamp": 1765241955.8631406,
      "val_loss": 0.03811386887917039,
      "val_ppl": 1.0388495187741582
    },
    {
      "step": 3100,
      "timestamp": 1765241959.2897012,
      "train_loss": 0.02846131785772741,
      "train_ppl": 1.0288702111608723,
      "lr": 0.0001083912775310416,
      "grad_norm": 0.05057996138930321,
      "steps_per_sec": 7.589580229976775
    },
    {
      "step": 3200,
      "timestamp": 1765241962.3569734,
      "train_loss": 0.0268776389118284,
      "train_ppl": 1.0272421006118737,
      "lr": 9.951090230706197e-05,
      "grad_norm": 0.05814467370510101,
      "steps_per_sec": 7.776011640275833
    },
    {
      "step": 3300,
      "timestamp": 1765241965.4187658,
      "train_loss": 0.028073076708242297,
      "train_ppl": 1.028470838938802,
      "lr": 9.086813991824483e-05,
      "grad_norm": 0.05655582249164581,
      "steps_per_sec": 7.959789781961354
    },
    {
      "step": 3400,
      "timestamp": 1765241968.4829707,
      "train_loss": 0.026458306508138775,
      "train_ppl": 1.0268114350149835,
      "lr": 8.250000000000003e-05,
      "grad_norm": 0.06963673233985901,
      "steps_per_sec": 8.140826283369417
    },
    {
      "step": 3500,
      "timestamp": 1765241971.559548,
      "train_loss": 0.026325418259948493,
      "train_ppl": 1.0266749929081398,
      "lr": 7.444231621215771e-05,
      "grad_norm": 0.06877610087394714,
      "steps_per_sec": 8.318981127549321
    },
    {
      "step": 3500,
      "timestamp": 1765241995.7579932,
      "val_loss": 0.03653799971579756,
      "val_ppl": 1.037213717095373
    },
    {
      "step": 3600,
      "timestamp": 1765241999.1199338,
      "train_loss": 0.026780450791120528,
      "train_ppl": 1.0271422697338695,
      "lr": 6.67295927937355e-05,
      "grad_norm": 0.05831209942698479,
      "steps_per_sec": 8.030605870110263
    },
    {
      "step": 3700,
      "timestamp": 1765242002.1871605,
      "train_loss": 0.025801993245258927,
      "train_ppl": 1.026137746151357,
      "lr": 5.939485681049002e-05,
      "grad_norm": 0.051539916545152664,
      "steps_per_sec": 8.197589194549971
    },
    {
      "step": 3800,
      "timestamp": 1765242005.2577994,
      "train_loss": 0.02440585969015956,
      "train_ppl": 1.024706120414708,
      "lr": 5.246951672795062e-05,
      "grad_norm": 0.06496697664260864,
      "steps_per_sec": 8.362255719868061
    },
    {
      "step": 3900,
      "timestamp": 1765242008.3321996,
      "train_loss": 0.02559497807174921,
      "train_ppl": 1.0259253420539869,
      "lr": 4.59832279155483e-05,
      "grad_norm": 0.06529644131660461,
      "steps_per_sec": 8.524641896573513
    },
    {
      "step": 4000,
      "timestamp": 1765242011.392821,
      "train_loss": 0.023451393134891987,
      "train_ppl": 1.023728539302248,
      "lr": 3.996376565777091e-05,
      "grad_norm": 0.05522160604596138,
      "steps_per_sec": 8.685119067991346
    },
    {
      "step": 4000,
      "timestamp": 1765242036.0292833,
      "val_loss": 0.035366826851215144,
      "val_ppl": 1.035999671602477
    },
    {
      "step": 4100,
      "timestamp": 1765242039.695169,
      "train_loss": 0.025940554765984416,
      "train_ppl": 1.0262799392089532,
      "lr": 3.4436906216130924e-05,
      "grad_norm": 0.06175021454691887,
      "steps_per_sec": 8.386855523581282
    },
    {
      "step": 4200,
      "timestamp": 1765242042.7712042,
      "train_loss": 0.024329800363630055,
      "train_ppl": 1.024628184921197,
      "lr": 2.942631645125639e-05,
      "grad_norm": 0.04519914835691452,
      "steps_per_sec": 8.537691634537804
    },
    {
      "step": 4300,
      "timestamp": 1765242045.8484333,
      "train_loss": 0.02357908229343593,
      "train_ppl": 1.023859266684066,
      "lr": 2.4953452477760202e-05,
      "grad_norm": 0.056249938905239105,
      "steps_per_sec": 8.686632084584293
    },
    {
      "step": 4400,
      "timestamp": 1765242048.924357,
      "train_loss": 0.02418467553332448,
      "train_ppl": 1.02447949671917,
      "lr": 2.1037467785863422e-05,
      "grad_norm": 0.060125682502985,
      "steps_per_sec": 8.833756112363018
    },
    {
      "step": 4500,
      "timestamp": 1765242051.9964383,
      "train_loss": 0.02456787689588964,
      "train_ppl": 1.0248721538868086,
      "lr": 1.7695131223209693e-05,
      "grad_norm": 0.07507811486721039,
      "steps_per_sec": 8.979142057116341
    },
    {
      "step": 4500,
      "timestamp": 1765242076.1276317,
      "val_loss": 0.03505772213973654,
      "val_ppl": 1.0356794887104641
    },
    {
      "step": 4600,
      "timestamp": 1765242079.4735317,
      "train_loss": 0.02469616831280291,
      "train_ppl": 1.025003644621972,
      "lr": 1.494075518808511e-05,
      "grad_norm": 0.06786025315523148,
      "steps_per_sec": 8.701597226114332
    },
    {
      "step": 4700,
      "timestamp": 1765242082.5133927,
      "train_loss": 0.02355141967535019,
      "train_ppl": 1.0238309444479337,
      "lr": 1.278613434153159e-05,
      "grad_norm": 0.06983038038015366,
      "steps_per_sec": 8.83992965296752
    },
    {
      "step": 4800,
      "timestamp": 1765242085.557592,
      "train_loss": 0.024969717422500252,
      "train_ppl": 1.0252840718099498,
      "lr": 1.1240495100797495e-05,
      "grad_norm": 0.05872927978634834,
      "steps_per_sec": 8.976616390591566
    },
    {
      "step": 4900,
      "timestamp": 1765242088.6035252,
      "train_loss": 0.025486634196713567,
      "train_ppl": 1.0258141953480726,
      "lr": 1.0310456130402496e-05,
      "grad_norm": 0.054848819971084595,
      "steps_per_sec": 9.111726283155276
    },
    {
      "step": 5000,
      "timestamp": 1765242091.6456296,
      "train_loss": 0.024876090055331587,
      "train_ppl": 1.025188081655429,
      "lr": 1e-05,
      "grad_norm": 0.06132252886891365,
      "steps_per_sec": 9.245379598013104
    },
    {
      "step": 5000,
      "timestamp": 1765242115.7307186,
      "val_loss": 0.03489381821543767,
      "val_ppl": 1.0355097506886926
    }
  ]
}